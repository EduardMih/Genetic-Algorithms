


\documentclass{article}

\usepackage[romanian]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}



\author{Eduard-Mihail Hamza}
\title{Raport Tema1}

\begin{document}
\maketitle

\section{Introducere}

În analiza matematică, maximul și minimul unei funcții sunt cele mai mari, respectiv cele mai mici valori, pe care funcția le poate lua, fie pe un anume interval (caz în care poartă denumirea de maxim/minim local) sau pe întreg domeniul de definiție al funcției (caz în care se numește maxim/minim global).\\ \\
În acest raport se va realiza o comparație între un \textbf{algoritm genetic de optimizare} și metodele \textbf{Hill Climbing} și \textbf{Simulated Annealing} și se vor prezenta câteva date experimentale ce caracterizază execuția acestor algoritmi de aflare a minimului global al unei funcții cu număr variabil de parametri.

 
\subsection{Motivație}
Problemele de optimizare a unei funcții presupun gasirea minimului sau maximului unei funcții pe un interval. Astfel de probleme se abordează de obicei, atunci când instrumentele matematice clasice nu mai pot oferii soluții, cu ajutorul algoritmilor genetici. Una dintre cele mai mari provocări ale acestor algoritmi de optimizare este găsirea minimului/maximului global fără a rămâne blocați in minime/maxime locale.\\
Acest raport își propune să observe care dintre cele trei metode amintite mai sus are rezultate mai bune în funcție de fiecare funcție de test în parte și în funcție de dimensiunea fiecărei funcții.

\section{Metode}
Implementarea \textbf{algoritmului genetic} s-a realizat dupa o schmeă clasică în care se generează o populație inițială care apoi evoluează de lungul mai multor generații (prin crossovere și mutații) sub controlul unei funcții fitness care măsoară meritul individual.\\
Mai jos sunt amintite câteva detalii de implementare:
\begin{itemize}
\item Număr generații: $1000$
\item Probabilitate mutație: $0.001$
\item Probabilitate crossover: $0.4$
\item Monstră statistică: $30$
\end{itemize}
În ceea ce privește metoda de selecție a fost folosită \textbf{roata norocului}, metodă prin care numărul estimat de copii pe care îl primește un individ este proporțional cu fitness-ul său împărțit la fitness-ul total al populației.\\ 
Mai jos este prezentat codul funcței fitness folosită:\\ \\
Celelalte 2 metode folosite au fost \textbf{Hill Climbing} și \textbf{Simulated Annealing}:\\
\textbf{Hill Climbing}, o metodă iterativă ce realizează o căutare locală. Este utilizată varianta iterată (Iterated Hill Climbing) în care HC este restartat, pentru a mări gradul de explorare a spațiului de căutare.\\
De asemenea, se vor folosii 2 tipuri de HC:  \textbf{Best Improvment Hill Climbing} și \textbf{First Improvment Hill Climbing}\\
\textbf{Best Improvment Hill Climbing} examinează fiecare vecin și îl alege pe cel care determină cea mai bună soluție.\\
\textbf{First Improvment Hill Climbing} nu examinează fiecare vecin înainte de a hotărî pe care îl alege. Pur și simplu alege un vecin la întâmplare pâna când gasește unul mai promițător decât cel curent.\\
\textbf{Simulated Annealing}, o meta-euristtică de tip traiectorie care permite o mai bună explorare a spațiului 
și ieșirea din puncte de optim local, dând posibilitatea vizitării unor soluții de calitate mai slabă decât cea curentă. \\
Pentru funcția de modificare a temperaturii s-a folosit înmultirea cu un numar subunitar (0.9), aceasta fiind inițializata la începutul algoritmului cu valoarea 1000.\\
În cazul tuturor metodelor pentru \textbf{reprezentarea soluțiilor} s-au folosit șiruri de biti, iar \textbf{precizia} utilizată a fost $10^{-2}$ (2 zecimale).

\section{Experiment}
Pentru testarea algoritmilor vom folosi următoarele funcții:
\begin{enumerate}
\item \textbf{Functia lui De Jong 1}
$$ f(x) = \sum_{i=1}^n x_i^2, 
x_i \in \left[ -5.12, 5.12 \right]$$

Minim global: 0

\item \textbf{Functia lui Schwefel}
$$ f(x) = \sum_{i=1}^n -x_i \cdot \sin (\sqrt{\mid x_i\mid}),
x_i \in \left[ -500, 500\right]  $$

Minim global: $-n \cdot 418.9829$
\item \textbf{Functia lui Rastrigin}
$$ f(x) = A \cdot n + \sum_{i=1}^n \left[ x_i^2 - A \cdot cos(2 \pi x_i) \right],
A = 10, x_i \in \left[ -5.12, 5.15 \right]$$

Minim global: 0
\item \textbf{Functia lui Michalewicz}
$$ f(x) = -\sum_{i=1}^n \sin (x_i) \cdot \left( \sin \left( \frac{i \cdot x_i^{2}}{\pi} \right) \right)  ^{2m},
m = 10, x_i \in \left[ 0, \pi \right] $$

Minim global: -4.687 (n=5), -9.66 (n=10)
\end{enumerate}


\section{Rezultate}
teoretic = minimul teoretic al funcției (cel corect)\\\
minim = cel mai bun minim returnat de algoritm\\
medie = media minimelor obținute\\
$\sigma$ = deviație standard\\
timp = timpul mediu de execuție în secunde\\


\clearpage
\subsection{5 dimensiuni}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Rastrigin 5 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{DeJong1 5 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Michalewicz 5 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Schwefel 5 dimensiuni - monstră statistică 30} 
\end{figure}

\clearpage
\subsection{10 dimensiuni}


\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Rastrigin 10 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{DeJong1 10 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Michalewicz 10 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Schwefel 10 dimensiuni - monstră statistică 30} 
\end{figure}

\clearpage
\subsection{30 dimensiuni}


\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Rastrigin 30 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{DeJong1 30 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Michalewicz 30 dimensiuni - monstră statistică 30} 
\end{figure}

\begin{figure}[!h]
\begin{tabular}{||c|||l|l|l|l||}
  \hline
  \multicolumn{5}{||c||}{Rastrigin (teoretic min=0)} \\ \hline
  Algoritm & minim & medie & $\sigma$ & timp(s) \\ \hline \hline
  GA & 0 & 0 & 0 & 0 \\ \hline
  BIHC & 0 & 0 & 0 & 0\\ \hline
  FIHC & 0 & 0 & 0 & 0 \\ \hline
  SA & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\caption{Schwefel 30 dimensiuni - monstră statistică 30} 
\end{figure}


\subsection{Interpretare}
\subsubsection{5 dimensiuni}
Toate cele trei metode produc soluții asemănătoare. Simulated Annealing are cea mai slabă soluție în cazul funcției lui Rastrigin.\\
În ceea ce privește timpul de execuție HC Best Improvment este cea mai costisitoare, în timp ce HC First Improvment și SA au timpi asemănători.
O observație interesantă este că în cazul funcției lui Schwefel timpul de execuție a fost de apoximativ 14 ori mai mare decât în cazul celorlalte 2 metode.\\
Din punct de vedere al deviației standard, SA are o valoare de aproape 4 ori mai mare în cazul funcției Schwefel.

\subsubsection{10 dimensiuni}
HC Best Improvment continua să ofere cele mai apropiate soluții de cele reale, însă timpul de execuție este substanțial mai mare.(109.499 secunde în cazul funcției Schwefel).\\
HC First Improvment și SA ofera rezultate identice pentru minimul funcțiilor Rastrigin și Michalewicz (și foarte apropiate pentru DeJong) însa diferă observabil la rezultatul mediu în cazul funcției Rastrigin. Timpii de execuție sunt asemănători, însă deviația standard este mult mai mare în cazul SA la Schwefel (151.24).

\subsubsection{30 dimensiuni}
Toate cele 3 metode încep să produca rezultate departate față de cele reale. SA este pe primul loc, urmată de HC First Improvment. HC Best Improvment nu poate fi luat în calcul la aceasta categorie datorită monstrei statistice foarte mici.\\
HC First Improvment și SA au în continuare timpii asemanatori de execuție, excepție făcând funcția Schwefel, pentru care HC are un timp dublu.
HC Best Improvment are un timp de execuție uriaș, în comparație cu celelate doua metode. În cazul funcției Schwefel o singura rulare a algoritmului a durat 2942.72 secunde, de aici și alegerea unei monstre statistice foarte mici.\\
Se observă ca SA are o deviație standard mult mai mare decât HC First Improvment.


\section{Concluzii}
\textbf{Pentru dimensiunea 5}, toate metodele au returnat o valoare apropiată de cea reală. Deci toate 3 sunt metode bune pentru determinarea minimului.\\
\textbf{Pentru dimensiunea 10}, HC First Improvment și SA încep să se îndepărteze ușor de rezultatele reale, în timp HC Best Improvment oferă cele mai bune raspunsuri, dar cu prețul unui timp mai mare.\\
\textbf{Pentru dimensiunea 30}, HC Best Improvment devine inutil de executat datorita timpului uriaș, în schimb SA reușește sa producă cele mai bune rezultate și cei mai buni timpi. Asadar, SA devine metoda recomandată pentru dimensiuni mari ale funcției.


\begin{thebibliography}{9}

\bibitem{Maxim și minim}
  Minim și maxim\\
  \url{https://en.wikipedia.org/wiki/Maxima_and_minima}

\bibitem{HC și SA}
  Hill Climbing și Simulated Annealing\\
  \url{https://profs.info.uaic.ro/~eugennc/teaching/ga/}\\
  \url{http://www.lia.deis.unibo.it/~aro/pubs/blum_roli_metaheuristics-preprint.pdf}
  
\bibitem{Intocmirea raportului}
  \begin{flushleft}
  Intocmirea unui raport \\ Formularea introducerii.
  \url{https://www.monash.edu/rlo/assignment-samples/engineering/eng-writing-technical-reports/introduction}
  \end{flushleft}
  
\bibitem{Hill Climbing}
  Tipuri de Hill Climbing\\
  \url{https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/}
  
\bibitem{SA}
  Simulatin Annealing\\
  \url{http://www.cs.cmu.edu/afs/cs.cmu.edu/project/learn-43/lib/photoz/.g/web/glossary/anneal.html}
  
 \bibitem{De Jong1}
  De Jong1\\
  \url{http://www.geatbx.com/docu/fcnindex-01.html#P89_3085}
  
\bibitem{Schwefel}
  Schwefel\\
  \url{http://www.geatbx.com/docu/fcnindex-01.html#P150_6749}
  
\bibitem{Rastrigin}
  Rastrigin\\
  \url{http://www.geatbx.com/docu/fcnindex-01.html#P140_6155}
  
\bibitem{Michalewicz}
  Michalewicz\\
  \url{http://www.geatbx.com/docu/fcnindex-01.html#P204_10395}\\
  \url{http://www.alliot.mobi/papers/gecco2014b.pdf}
  
  
\end{thebibliography}  
\end{document}